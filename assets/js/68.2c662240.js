(window.webpackJsonp=window.webpackJsonp||[]).push([[68],{427:function(s,e,a){"use strict";a.r(e);var n=a(7),t=Object(n.a)({},(function(){var s=this,e=s._self._c;return e("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[e("h1",{attrs:{id:"曲折的势函数训练过程"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#曲折的势函数训练过程"}},[s._v("#")]),s._v(" 曲折的势函数训练过程")]),s._v(" "),e("h2",{attrs:{id:"_1-势函数训练"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_1-势函数训练"}},[s._v("#")]),s._v(" 1. 势函数训练")]),s._v(" "),e("p",[s._v("服务器的机器的显存不能支持deepmd-kit的训练，在scnet上进行了测试，发现无法显存接近70G，因此也训练失败。")]),s._v(" "),e("p",[s._v("我尝试过用两个节点开更多dcu来支持gpu版本的运行，但是两个节点的通讯是一个更大的技术难题，因此在scnet上的gpu版本训练计划作废。")]),s._v(" "),e("p",[s._v("但是，我们后来在scent上使用cpu版本成功进行了训练，训练时间为1天半。")]),s._v(" "),e("h2",{attrs:{id:"_2-势函数的后处理"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-势函数的后处理"}},[s._v("#")]),s._v(" 2. 势函数的后处理")]),s._v(" "),e("h3",{attrs:{id:"_2-1-势函数的freeze"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-势函数的freeze"}},[s._v("#")]),s._v(" 2.1 势函数的freeze")]),s._v(" "),e("p",[s._v("这一步无论是在超算上用cpu版本来操作，还是用本地服务器的gpu版本来操作都是没问题的。")]),s._v(" "),e("p",[s._v("并且因为后续的compress过程过于曲折，因此我们在这一阶段也直接尝试使用“完成freeze单没有被compress的模型”进行了lammps模拟，发现对于32000原子的体系需要大约4小时才能跑1000个steps，效率极低。")]),s._v(" "),e("h3",{attrs:{id:"_2-2-势函数的compress陷入困境"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-势函数的compress陷入困境"}},[s._v("#")]),s._v(" 2.2 势函数的compress陷入困境")]),s._v(" "),e("p",[s._v("在最初尝试了在scnet上的cpu版本进行compress，但是发现compress失败，原因是递归过深：")]),s._v(" "),e("div",{staticClass:"language-bash line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[s._v("RecursionError: maximum recursion depth exceeded "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" comparison\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br")])]),e("p",[s._v("我顺手在GitHub上的issue上查找了一下，找到了一个2024年7月的issue，但是是gpu版本的问题，并且是版本兼容的相关问题（第一个是新版本的小bug，第二个是dp版本和tf版本不兼容，或者说他换了一个tf版本就跑通了）")]),s._v(" "),e("p",[s._v("后来尝试在本地进行了compress操作，但是发现本地服务器和scnet上的不兼容问题暴露了：本地服务器是v2.2.10，而scnet上的版本是v3.0.0，v3.0.0在model部分存在更多的描述性信息，这些信息无法被本地v2.2.10读取，直接报错。")]),s._v(" "),e("p",[s._v("而scent的gpu版本几乎不支持compress这个操作，至少我直接sbatch上去之后没有正常运行，报错信息是：")]),s._v(" "),e("div",{staticClass:"language-bash line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[s._v("File "),e("span",{pre:!0,attrs:{class:"token string"}},[s._v('"/opt/deepmd-kit_v3.0.0b4_pytorch/lib/python3.8/site-packages/deepmd/tf/env.py"')]),s._v(", line "),e("span",{pre:!0,attrs:{class:"token number"}},[s._v("84")]),s._v(", "),e("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v("module"),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v("\n    "),e("span",{pre:!0,attrs:{class:"token function"}},[s._v("import")]),s._v(" tensorflow.compat.v1 as tf\nModuleNotFoundError: No module named "),e("span",{pre:!0,attrs:{class:"token string"}},[s._v("'tensorflow'")]),s._v("\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br")])]),e("h3",{attrs:{id:"_2-3-势函数的compress尝试突困"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-势函数的compress尝试突困"}},[s._v("#")]),s._v(" 2.3 势函数的compress尝试突困")]),s._v(" "),e("p",[s._v("根据上面的信息，我们可以尝试将本地的deepmd-kit升级成为v3.0.0版本（其实，我是直接安装了一个新的v3.0.0版本，老版本也暂时留着）")]),s._v(" "),e("p",[s._v("首先，去南京大学的镜像网站扒deepmd-kit的两个release文件，然后把它们合并一下再执行，建议在home目录执行：")]),s._v(" "),e("div",{staticClass:"language-bash line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[e("span",{pre:!0,attrs:{class:"token function"}},[s._v("cat")]),s._v(" deepmd-kit-3.0.0-cuda126-Linux-x86_64.sh.0 deepmd-kit-3.0.0-cuda126-Linux-x86_64.sh.1 "),e("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" deepmd-kit-3.0.0-cuda126-Linux-x86_64.sh\n"),e("span",{pre:!0,attrs:{class:"token function"}},[s._v("sh")]),s._v(" deepmd-kit-3.0.0-cuda126-Linux-x86_64.sh "),e("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("-b")]),s._v("\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br")])]),e("p",[s._v("然后home目录中应该会出现一个deepmd-kit目录，之后需要激活一下刚刚装好的环境：")]),s._v(" "),e("div",{staticClass:"language-bash line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("source")]),s._v(" ~/deepmd-kit/bin/activate\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br")])]),e("p",[s._v("此时即可查看dp的版本：")]),s._v(" "),e("div",{staticClass:"language-bash line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[s._v("dp "),e("span",{pre:!0,attrs:{class:"token parameter variable"}},[s._v("--version")]),s._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#DeePMD-kit v3.0.0")]),s._v("\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br")])]),e("p",[s._v("然后就可以正常地使用dp去compress了，而这一次直接一次成功。（感觉新版本的显存分配也智能了很多，后续可以尝试一下）")]),s._v(" "),e("h2",{attrs:{id:"_3-势函数用于合金的relax过程"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#_3-势函数用于合金的relax过程"}},[s._v("#")]),s._v(" 3. 势函数用于合金的relax过程")]),s._v(" "),e("p",[s._v("这里回到scnet上的gpu版本（主要是优化做得太好了），已经能够正常使用CrFeCoNiPd-compress.pb文件了，3分钟运行了2000steps，至少技术性上这个问题被完全解决。")]),s._v(" "),e("p",[s._v("即使用scnet的cpu版本进行训练，在本地进行训练结果的后处理，将势函数模型放在scnet上运行lammps，这是目前实践下来能够走通的一套完整工作流。")]),s._v(" "),e("h2",{attrs:{id:"附录-安装deepmd-kit-v3-0-0的安装记录"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#附录-安装deepmd-kit-v3-0-0的安装记录"}},[s._v("#")]),s._v(" 附录-安装deepmd-kit-v3.0.0的安装记录")]),s._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[s._v("PREFIX=/home/ifxie/deepmd-kit\nUnpacking payload ...\nNotes:\nThe off-line packages and conda packages require the GNU C Library 2.17 or above[1]. The GPU version requires compatible NVIDIA driver to be installed in advance[2]. It is possible to force conda to override detection when installation[3] (such as CONDA_OVERRIDE_CUDA), but these requirements are still necessary during runtime.\n\n[1] The GNU C Library. https://www.gnu.org/software/libc/\n[2] Minor Version Compatibility. NVIDIA Data Center GPU Driver Documentation. https://docs.nvidia.com/deploy/cuda-compatibility/index.html#minor-version-compatibility\n[3] Overriding detected packages. conda documentation. https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-virtual.html#overriding-detected-packages\n\n\nInstalling base environment...\n\nPreparing transaction: ...working... done\nExecuting transaction: ...working... By downloading and using the cuDNN conda packages, you accept the terms and conditions of the NVIDIA cuDNN EULA -\n  https://docs.nvidia.com/deeplearning/cudnn/sla/index.html\n\n\nTo enable CUDA support, UCX requires the CUDA Runtime library (libcudart).\nThe library can be installed with the appropriate command below:\n\n* For CUDA 11, run:    conda install cudatoolkit cuda-version=11\n* For CUDA 12, run:    conda install cuda-cudart cuda-version=12\n\n\n\nTo enable CUDA support, please follow UCX's instruction above.\n\nTo additionally enable NCCL support, run:    conda install nccl\n\n\n\nOn Linux, Open MPI is built with CUDA awareness but it is disabled by default.\nTo enable it, please set the environment variable\nOMPI_MCA_opal_cuda_support=true\nbefore launching your MPI processes.\nEquivalently, you can set the MCA parameter in the command line:\nmpiexec --mca opal_cuda_support 1 ...\nNote that you might also need to set UCX_MEMTYPE_CACHE=n for CUDA awareness via\nUCX. Please consult UCX documentation for further details.\n\n\ndone\nPlease activate the environment before using the packages:\n\nsource /path/to/deepmd-kit/bin/activate /path/to/deepmd-kit\n\nThis package enables TensorFlow, PyTorch, and JAX backends.\n\nThe following executable files have been installed:\n1. DeePMD-kit CLi: dp -h\n2. LAMMPS: lmp -h\n3. DeePMD-kit i-Pi interface: dp_ipi\n4. MPICH: mpirun -h\n5. Horovod: horovod -h\n\nThe following Python libraries have been installed:\n1. deepmd\n2. dpdata\n3. pylammps\n\nIf you have any questions, seek help from https://github.com/deepmodeling/deepmd-kit/discussions\n\ninstallation finished.\n")])]),s._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[s._v("1")]),e("br"),e("span",{staticClass:"line-number"},[s._v("2")]),e("br"),e("span",{staticClass:"line-number"},[s._v("3")]),e("br"),e("span",{staticClass:"line-number"},[s._v("4")]),e("br"),e("span",{staticClass:"line-number"},[s._v("5")]),e("br"),e("span",{staticClass:"line-number"},[s._v("6")]),e("br"),e("span",{staticClass:"line-number"},[s._v("7")]),e("br"),e("span",{staticClass:"line-number"},[s._v("8")]),e("br"),e("span",{staticClass:"line-number"},[s._v("9")]),e("br"),e("span",{staticClass:"line-number"},[s._v("10")]),e("br"),e("span",{staticClass:"line-number"},[s._v("11")]),e("br"),e("span",{staticClass:"line-number"},[s._v("12")]),e("br"),e("span",{staticClass:"line-number"},[s._v("13")]),e("br"),e("span",{staticClass:"line-number"},[s._v("14")]),e("br"),e("span",{staticClass:"line-number"},[s._v("15")]),e("br"),e("span",{staticClass:"line-number"},[s._v("16")]),e("br"),e("span",{staticClass:"line-number"},[s._v("17")]),e("br"),e("span",{staticClass:"line-number"},[s._v("18")]),e("br"),e("span",{staticClass:"line-number"},[s._v("19")]),e("br"),e("span",{staticClass:"line-number"},[s._v("20")]),e("br"),e("span",{staticClass:"line-number"},[s._v("21")]),e("br"),e("span",{staticClass:"line-number"},[s._v("22")]),e("br"),e("span",{staticClass:"line-number"},[s._v("23")]),e("br"),e("span",{staticClass:"line-number"},[s._v("24")]),e("br"),e("span",{staticClass:"line-number"},[s._v("25")]),e("br"),e("span",{staticClass:"line-number"},[s._v("26")]),e("br"),e("span",{staticClass:"line-number"},[s._v("27")]),e("br"),e("span",{staticClass:"line-number"},[s._v("28")]),e("br"),e("span",{staticClass:"line-number"},[s._v("29")]),e("br"),e("span",{staticClass:"line-number"},[s._v("30")]),e("br"),e("span",{staticClass:"line-number"},[s._v("31")]),e("br"),e("span",{staticClass:"line-number"},[s._v("32")]),e("br"),e("span",{staticClass:"line-number"},[s._v("33")]),e("br"),e("span",{staticClass:"line-number"},[s._v("34")]),e("br"),e("span",{staticClass:"line-number"},[s._v("35")]),e("br"),e("span",{staticClass:"line-number"},[s._v("36")]),e("br"),e("span",{staticClass:"line-number"},[s._v("37")]),e("br"),e("span",{staticClass:"line-number"},[s._v("38")]),e("br"),e("span",{staticClass:"line-number"},[s._v("39")]),e("br"),e("span",{staticClass:"line-number"},[s._v("40")]),e("br"),e("span",{staticClass:"line-number"},[s._v("41")]),e("br"),e("span",{staticClass:"line-number"},[s._v("42")]),e("br"),e("span",{staticClass:"line-number"},[s._v("43")]),e("br"),e("span",{staticClass:"line-number"},[s._v("44")]),e("br"),e("span",{staticClass:"line-number"},[s._v("45")]),e("br"),e("span",{staticClass:"line-number"},[s._v("46")]),e("br"),e("span",{staticClass:"line-number"},[s._v("47")]),e("br"),e("span",{staticClass:"line-number"},[s._v("48")]),e("br"),e("span",{staticClass:"line-number"},[s._v("49")]),e("br"),e("span",{staticClass:"line-number"},[s._v("50")]),e("br"),e("span",{staticClass:"line-number"},[s._v("51")]),e("br"),e("span",{staticClass:"line-number"},[s._v("52")]),e("br"),e("span",{staticClass:"line-number"},[s._v("53")]),e("br"),e("span",{staticClass:"line-number"},[s._v("54")]),e("br"),e("span",{staticClass:"line-number"},[s._v("55")]),e("br"),e("span",{staticClass:"line-number"},[s._v("56")]),e("br"),e("span",{staticClass:"line-number"},[s._v("57")]),e("br"),e("span",{staticClass:"line-number"},[s._v("58")]),e("br"),e("span",{staticClass:"line-number"},[s._v("59")]),e("br"),e("span",{staticClass:"line-number"},[s._v("60")]),e("br"),e("span",{staticClass:"line-number"},[s._v("61")]),e("br"),e("span",{staticClass:"line-number"},[s._v("62")]),e("br"),e("span",{staticClass:"line-number"},[s._v("63")]),e("br")])])])}),[],!1,null,null,null);e.default=t.exports}}]);